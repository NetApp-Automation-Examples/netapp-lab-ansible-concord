---
- name: Takeover/giveback of a given node for each cluster
  hosts: "{{ ansible_limit }}"
  gather_facts: no
  connection: 'local'
  collections:
    - netapp.ontap
  vars:
    failover_status_retries: 10
    failover_status_delay: 30
    failover_warnings: []
    failover_warnings_to_ignore: []
    nodes: 
      cluster1: cluster1-01
      cluster2: cluster2-01
    node: "{{ nodes[inventory_hostname] if inventory_hostname in nodes else '' }}"
    node_query:
      fields: "uptime,state,ha,version"
    lif_query: 
      fields: "location,state"

  module_defaults:    
    group/netapp.ontap.netapp_ontap:      
      hostname: "{{ ontap_hostname }}"
      username: "{{ ontap_username }}"
      password: "{{ ontap_password }}"
      https: "{{ https }}"
      validate_certs: "{{ validate_certs }}"

  tasks:
  - name: Log of nodes
    ansible.builtin.debug:
      msg: "nodes = {{ nodes }} and node = {{ node }}"
  
  - name: End playbook for host if no node found
    ansible.builtin.meta: end_host
    when: node == ''

  - name: Get node info
    include_tasks: tasks/ontap_get_cluster_info_rest.yml
    vars:
      gather_subset:
      - cluster/nodes
      parameters:
        name: "{{ node }}"
        fields: "{{ node_query.fields }}"

  - name: Set node info fact
    ansible.builtin.set_fact:
      node_info: "{{ ontap_rest_info['cluster/nodes']['records'] | first }}"

  - name: Set node_state 
    ansible.builtin.set_fact:
      node_state: "{{ node_info.state }}"

  - name: Get HA Partner info 
    netapp.ontap.na_ontap_restit:
      api: cluster/nodes/{{ node_info.ha.partners.0.uuid }}
      query:
        fields: "state,ha"
    register: get_ha_partner

  - name: Set node_ha_partner
    ansible.builtin.set_fact:
      ha_partner: "{{ get_ha_partner.response }}" 

  - name: Set in_takeover 
    ansible.builtin.set_fact:
      in_takover: True
    when: node_state in ['taken_over','waiting_for_giveback'] 
          and ha_partner.ha.takeover.state in ['in_progress','in_takeover']

  - name: Set doing_giveback
    ansible.builtin.set_fact:
      doing_giveback: True
    when: node_state in ['booting','degraded','waiting_for_giveback'] 
          and ha_partner.ha.giveback.state in ['in_progress']

  - name: Set ready_for_takeover
    ansible.builtin.set_fact: 
      ready_for_takeover: True
    when: node_state == 'up' 
          and ha_partner.ha.giveback.state in ['nothing_to_giveback', 'not_attempted']
          and ha_partner.ha.takeover.state == 'not_attempted'

  - name: Log of current uptime, os version, and failover state 
    ansible.builtin.debug:
      msg: |
        {{ node_info.name }} (HA partner is {{ node_info.ha.partners | map(attribute='name') }}) 
        uptime = {{ node_info.uptime if node_info.uptime is defined else '0' }} 
        version = at {{ node_info.version.full }} 
        state = {{ node_info.state }} 
        partner state = {{ ha_partner.state }}
        partner takeover = {{ ha_partner.ha.takeover }}
        partner giveback = {{ ha_partner.ha.giveback }}
        in_takeover = {{ in_takeover if in_takeover is defined }}
        doing_giveback = {{ doing_giveback if doing_giveback is defined }}
        ready_for_takeover = {{ ready_for_takeover if ready_for_takeover is defined }}
    
  
  - name: End
    meta: end_play

  - name: Migrate all lifs and initiate takeover
    block: 
    - name: net int migrate-all -node <node> 
      netapp.ontap.na_ontap_rest_cli: 
        command: 'network/interface/migrate-all'
        body: 
          node: "{{ node }}"
        verb: "POST"
      register: net_int_migrate_all

    - name: After the LIF migrate command, get all LIFs with the home node set to <node>
      include_tasks: tasks/ontap_get_cluster_info_rest.yml
      vars:
        gather_subset:
        - network/ip/interfaces
        parameters:
          location.home_node.name: "{{ node }}"
          fields: "{{ lif_query.fields }}"

    - name: Set node_lifs fact
      ansible.builtin.set_fact: 
        node_lifs: "{{ ontap_rest_info['network/ip/interfaces']['records'] }}"

    - name: Log node_lifs
      ansible.builtin.debug: 
        msg: >
          {% for l in node_lifs %}
            {{ l.name +' is '+l.state|upper+' at '+l.location.node.name }}{{ ' (home is '+l.location.home_node.name+')' if l.location.is_home == false }}
          {% endfor %} 
    
    - name: storage failover takeover -ofnode <node> 
      netapp.ontap.na_ontap_rest_cli: 
        command: 'storage/failover/takeover'
        body: 
          ofnode: "{{ node }}"
        verb: "POST"
      register: takeover

    - name: Check failover status until we get "waiting for giveback"
      netapp.ontap.na_ontap_restit:
        api: cluster/nodes/{{ node_info.uuid }}
        query:
          fields: "state,ha"
      register: takeover_status
      until: takeover_status.response.state == 'waiting_for_giveback'
      retries: "{{ failover_status_retries }}"
      delay: "{{ failover_status_delay }}" 
    when: node_state == 'up' 

  - name: Check giveback status of primary
    netapp.ontap.na_ontap_restit:
      api: cluster/nodes/{{ node_info.uuid }}
      query:
        fields: "state,ha"
    register: giveback_status

  - name: Check giveback status of partner
    netapp.ontap.na_ontap_restit:
      api: cluster/nodes/{{ node_info.ha.partners.0.uuid }}
      query:
        fields: "state,ha"
    register: partner_giveback_status

  - name: log primary
    ansible.builtin.debug: 
      var: giveback_status

  - name: log partner
    ansible.builtin.debug: 
      var: partner_giveback_status
 
  # - name: Do the giveback
  #   block: 
  #   - name: storage failover giveback -ofnode <node>
  #     netapp.ontap.na_ontap_rest_cli: 
  #       command: 'storage/failover/giveback'
  #       body: 
  #         ofnode: "{{ node }}"
  #       verb: "POST"
  #     register: giveback
    
  #   - name: Check giveback status until we get "up"
  #     netapp.ontap.na_ontap_restit:
  #       api: cluster/nodes/{{ node_info.uuid }}
  #       query:
  #         fields: "state,ha.giveback.state"
  #     register: giveback_status
  #     until: giveback_status.response.state == 'up'
  #     retries: "{{ failover_status_retries }}"
  #     delay: "{{ failover_status_delay }}" 

  #   when: node_state == 'waiting_for_giveback' or takeover_status is defined




# - storage failover giveback -ofnode < node>
# - storage failover show-giveback
# Validate ports are up and revert lifs
# - net port show -node ‹node >
# - net int revert +
# - net int show -fields home-node,curr-node,curr-port,home-port,status-admin,status-oper -home-node ‹node>

    # - name: Log of failover_warning_results
    #   ansible.builtin.debug: 
    #     var: failover_warning_results

    # - name: "Check for warnings beyond what we are expecting {{ failover_warnings_to_ignore | join(',') }}"
    #   ansible.builtin.set_fact:
    #     failover_warnings: "{{ failover_warnings + [item] }}"
      #loop: "{{ failover_warning_results.response.validation_results }}"
      #when: item.update_check not in validation_warnings_to_ignore

    # - name: Log of failover_warnings
    #   debug:
    #     msg: "{{ failover_warnings }}"

    # - name: Prompt for review if there are validation warnings that we don't expect
    #   ansible.builtin.pause:
    #     prompt: "Please review the results of cluster upgrade validation and press 
    #               ENTER to continue with the upgrade. To abort upgrade, hit ctrl+c and then 'A':
    #               \n\n----------------------------------------------\n\n
    #               {% for warning in validation_warnings %}
    #                 {{ warning.status }}: \n{{ warning.issue.message }}\n\n
    #                 {{ warning.action.message }}
    #                 \n\n----------------------------------------------\n\n

    #               {% endfor %}"
    #   when: validation_warnings | length > 0
